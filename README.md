# ML Sampling Techniques Comparison

This project evaluates the effectiveness of 5 different sampling techniques for imbalanced datasets using 5 machine learning models. The goal is to compare the performance of each technique and model combination to identify the best approach for addressing class imbalance.
![image](https://user-images.githubusercontent.com/98878944/219968664-21d06338-5b77-4bef-9cee-85331b8e3005.png)

### The sampling techniques used in this project are:

- Near Miss Sampling
- Random Under-Sampling
- SMOTE Sampling
- TomekLinks Sampling
- Random Over-Sampling

### The machine learning models used in this project are:

- Logistic Regression
- LGBM Classifier
- Support Vector Machine
- Random Forest Classifier
- Quadratic Discriminant Analysis


### Getting Started
To get started with this project, you'll need to have the following prerequisites:

Python 3
- Jupyter Notebook
- Pandas, NumPy, Scikit-learn, and LightGBM libraries installed

### Running the Project
To run the project, simply open the Jupyter Notebook file and execute each cell in order. The results will be displayed in the notebook output.

### Conclusion
The results of this project show that LGBM Classifier is the most effective approach for addressing class imbalance in the credit card dataset here. These findings can be used to guide future research and practical applications in this domain.
