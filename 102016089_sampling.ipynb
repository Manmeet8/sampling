{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\nfrom sklearn.cluster import KMeans\nfrom sklearn.utils import resample\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler, TomekLinks, EditedNearestNeighbours, NearMiss\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom collections import Counter\nfrom sklearn.datasets import make_classification\nfrom imblearn.over_sampling import BorderlineSMOTE\nimport lightgbm as lgb\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.semi_supervised import LabelPropagation","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-19T18:50:34.666263Z","iopub.execute_input":"2023-02-19T18:50:34.666618Z","iopub.status.idle":"2023-02-19T18:50:35.534928Z","shell.execute_reply.started":"2023-02-19T18:50:34.666543Z","shell.execute_reply":"2023-02-19T18:50:35.533774Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/creditcard-data/Creditcard_data.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-19T18:50:35.536345Z","iopub.execute_input":"2023-02-19T18:50:35.536604Z","iopub.status.idle":"2023-02-19T18:50:35.573120Z","shell.execute_reply.started":"2023-02-19T18:50:35.536580Z","shell.execute_reply":"2023-02-19T18:50:35.571923Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.Class.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T18:50:35.574763Z","iopub.execute_input":"2023-02-19T18:50:35.575155Z","iopub.status.idle":"2023-02-19T18:50:35.583237Z","shell.execute_reply.started":"2023-02-19T18:50:35.575126Z","shell.execute_reply":"2023-02-19T18:50:35.581939Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"0    763\n1      9\nName: Class, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"x = df.iloc[:,:-1]\ny = df.iloc[:,-1]\nx","metadata":{"execution":{"iopub.status.busy":"2023-02-19T18:50:35.586319Z","iopub.execute_input":"2023-02-19T18:50:35.586616Z","iopub.status.idle":"2023-02-19T18:50:35.618762Z","shell.execute_reply.started":"2023-02-19T18:50:35.586592Z","shell.execute_reply":"2023-02-19T18:50:35.617948Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"     Time        V1        V2        V3        V4        V5        V6  \\\n0       0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n1       0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n2       1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n3       1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n4       2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n..    ...       ...       ...       ...       ...       ...       ...   \n767   575 -0.572263  0.731748  1.541254  0.150506  1.108974  0.372152   \n768   579 -1.296845 -0.511605  2.404726 -0.310762 -0.319551 -0.542842   \n769   579  1.214170  0.210481  0.484651  0.479768 -0.261955 -0.527039   \n770   580  1.267030 -0.071114  0.037680  0.512683  0.242392  0.705212   \n771   581  1.153758  0.132273  0.382969  1.405063 -0.224287 -0.197295   \n\n           V7        V8        V9  ...       V20       V21       V22  \\\n0    0.239599  0.098698  0.363787  ...  0.251412 -0.018307  0.277838   \n1   -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775 -0.638672   \n2    0.791461  0.247676 -1.514654  ...  0.524980  0.247998  0.771679   \n3    0.237609  0.377436 -1.387024  ... -0.208038 -0.108300  0.005274   \n4    0.592941 -0.270533  0.817739  ...  0.408542 -0.009431  0.798278   \n..        ...       ...       ...  ...       ...       ...       ...   \n767  1.084879 -0.146329 -0.274447  ...  0.056544 -0.143508 -0.107582   \n768 -0.173310  0.260423 -1.202688  ... -0.349668 -0.071270 -0.161175   \n769  0.021782 -0.106888 -0.037631  ... -0.071540 -0.224292 -0.594609   \n770 -0.226582  0.109483  0.657565  ... -0.066990 -0.164468 -0.177225   \n771  0.020653  0.029260  0.412254  ... -0.230877 -0.107809 -0.125231   \n\n          V23       V24       V25       V26       V27       V28  Amount  \n0   -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n1    0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69  \n2    0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n3   -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50  \n4   -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99  \n..        ...       ...       ...       ...       ...       ...     ...  \n767 -0.418263 -0.731029  0.877525 -0.364150 -0.177509 -0.256545   26.72  \n768  0.088496  0.285390  0.281069 -0.370130  0.043410  0.092318   80.00  \n769  0.159877  0.091873  0.140964  0.227406 -0.017389  0.016030    5.98  \n770 -0.222918 -1.245505  0.678360  0.525059  0.002920 -0.003333   12.36  \n771 -0.057041  0.073082  0.633977 -0.310685  0.033590  0.015250   13.79  \n\n[772 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>0.251412</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.069083</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.524980</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.208038</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>0.408542</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>575</td>\n      <td>-0.572263</td>\n      <td>0.731748</td>\n      <td>1.541254</td>\n      <td>0.150506</td>\n      <td>1.108974</td>\n      <td>0.372152</td>\n      <td>1.084879</td>\n      <td>-0.146329</td>\n      <td>-0.274447</td>\n      <td>...</td>\n      <td>0.056544</td>\n      <td>-0.143508</td>\n      <td>-0.107582</td>\n      <td>-0.418263</td>\n      <td>-0.731029</td>\n      <td>0.877525</td>\n      <td>-0.364150</td>\n      <td>-0.177509</td>\n      <td>-0.256545</td>\n      <td>26.72</td>\n    </tr>\n    <tr>\n      <th>768</th>\n      <td>579</td>\n      <td>-1.296845</td>\n      <td>-0.511605</td>\n      <td>2.404726</td>\n      <td>-0.310762</td>\n      <td>-0.319551</td>\n      <td>-0.542842</td>\n      <td>-0.173310</td>\n      <td>0.260423</td>\n      <td>-1.202688</td>\n      <td>...</td>\n      <td>-0.349668</td>\n      <td>-0.071270</td>\n      <td>-0.161175</td>\n      <td>0.088496</td>\n      <td>0.285390</td>\n      <td>0.281069</td>\n      <td>-0.370130</td>\n      <td>0.043410</td>\n      <td>0.092318</td>\n      <td>80.00</td>\n    </tr>\n    <tr>\n      <th>769</th>\n      <td>579</td>\n      <td>1.214170</td>\n      <td>0.210481</td>\n      <td>0.484651</td>\n      <td>0.479768</td>\n      <td>-0.261955</td>\n      <td>-0.527039</td>\n      <td>0.021782</td>\n      <td>-0.106888</td>\n      <td>-0.037631</td>\n      <td>...</td>\n      <td>-0.071540</td>\n      <td>-0.224292</td>\n      <td>-0.594609</td>\n      <td>0.159877</td>\n      <td>0.091873</td>\n      <td>0.140964</td>\n      <td>0.227406</td>\n      <td>-0.017389</td>\n      <td>0.016030</td>\n      <td>5.98</td>\n    </tr>\n    <tr>\n      <th>770</th>\n      <td>580</td>\n      <td>1.267030</td>\n      <td>-0.071114</td>\n      <td>0.037680</td>\n      <td>0.512683</td>\n      <td>0.242392</td>\n      <td>0.705212</td>\n      <td>-0.226582</td>\n      <td>0.109483</td>\n      <td>0.657565</td>\n      <td>...</td>\n      <td>-0.066990</td>\n      <td>-0.164468</td>\n      <td>-0.177225</td>\n      <td>-0.222918</td>\n      <td>-1.245505</td>\n      <td>0.678360</td>\n      <td>0.525059</td>\n      <td>0.002920</td>\n      <td>-0.003333</td>\n      <td>12.36</td>\n    </tr>\n    <tr>\n      <th>771</th>\n      <td>581</td>\n      <td>1.153758</td>\n      <td>0.132273</td>\n      <td>0.382969</td>\n      <td>1.405063</td>\n      <td>-0.224287</td>\n      <td>-0.197295</td>\n      <td>0.020653</td>\n      <td>0.029260</td>\n      <td>0.412254</td>\n      <td>...</td>\n      <td>-0.230877</td>\n      <td>-0.107809</td>\n      <td>-0.125231</td>\n      <td>-0.057041</td>\n      <td>0.073082</td>\n      <td>0.633977</td>\n      <td>-0.310685</td>\n      <td>0.033590</td>\n      <td>0.015250</td>\n      <td>13.79</td>\n    </tr>\n  </tbody>\n</table>\n<p>772 rows × 30 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2023-02-19T18:50:35.619798Z","iopub.execute_input":"2023-02-19T18:50:35.620075Z","iopub.status.idle":"2023-02-19T18:50:35.627164Z","shell.execute_reply.started":"2023-02-19T18:50:35.620048Z","shell.execute_reply":"2023-02-19T18:50:35.626251Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0      0\n1      1\n2      0\n3      0\n4      0\n      ..\n767    0\n768    0\n769    0\n770    0\n771    0\nName: Class, Length: 772, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T18:50:35.628289Z","iopub.execute_input":"2023-02-19T18:50:35.629176Z","iopub.status.idle":"2023-02-19T18:50:35.638874Z","shell.execute_reply.started":"2023-02-19T18:50:35.629141Z","shell.execute_reply":"2023-02-19T18:50:35.637446Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"os = RandomOverSampler(sampling_strategy='minority')\nx_over, y_over = os.fit_resample(x_train,y_train)\nx_over","metadata":{"execution":{"iopub.status.busy":"2023-02-19T18:50:35.641028Z","iopub.execute_input":"2023-02-19T18:50:35.641437Z","iopub.status.idle":"2023-02-19T18:50:35.682931Z","shell.execute_reply.started":"2023-02-19T18:50:35.641404Z","shell.execute_reply":"2023-02-19T18:50:35.682085Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"      Time        V1        V2        V3        V4        V5        V6  \\\n0        4  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708   \n1      266  1.289673 -0.694399  0.986683 -0.626997 -1.561741 -0.612824   \n2      488  0.986168 -0.550923  1.140934  0.757901 -1.038890  0.476782   \n3       48 -0.580629  0.482684  1.333123 -0.253080 -0.028469 -0.519166   \n4      156 -3.494861 -2.894450  1.637989 -0.274976 -0.389203 -0.703275   \n...    ...       ...       ...       ...       ...       ...       ...   \n1139   539 -1.738582  0.052740  1.187057 -0.656652  0.920623 -0.291788   \n1140   529 -2.000567 -2.495484  2.467149  1.140053  2.462010  0.594262   \n1141   118  1.254914  0.350287  0.302488  0.693114 -0.371470 -1.070256   \n1142   406 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n1143     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n\n            V7        V8        V9  ...       V20       V21       V22  \\\n0    -0.005159  0.081213  0.464960  ... -0.219633 -0.167716 -0.270710   \n1    -0.949037  0.068872 -0.744016  ... -0.485382 -0.411943 -0.812048   \n2    -0.837096  0.433228  0.896975  ... -0.106760  0.003400 -0.001184   \n3     0.503249  0.117773  0.117112  ... -0.298751 -0.042142 -0.148707   \n4     0.444194  0.154266  0.695818  ...  0.670036  0.017010 -0.063521   \n...        ...       ...       ...  ...       ...       ...       ...   \n1139  0.269083  0.140631  0.023464  ...  0.002974 -0.179545 -0.192036   \n1140 -2.110183  0.788347  0.958809  ...  0.620899  0.422452  1.195394   \n1141  0.086781 -0.202836  0.035154  ... -0.079756 -0.287592 -0.832682   \n1142 -2.537387  1.391657 -2.770089  ...  0.126911  0.517232 -0.035049   \n1143 -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775 -0.638672   \n\n           V23       V24       V25       V26       V27       V28  Amount  \n0    -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168    4.99  \n1     0.217873  0.515077 -0.174402  0.828402 -0.039262  0.013061   14.90  \n2     0.017652  0.026666  0.078602  0.328056  0.008762  0.020131   64.99  \n3     0.001451  0.302764 -0.680714 -0.015554 -0.006307  0.164222   21.66  \n4     0.676254  0.596377  0.114229  0.834915  0.309675  0.632261  500.00  \n...        ...       ...       ...       ...       ...       ...     ...  \n1139 -0.261879 -0.237477 -0.335040  0.240323 -0.345129 -0.383563    1.00  \n1140  0.297836 -0.857105 -0.219322  0.861019 -0.124622 -0.171060    1.50  \n1141  0.128083  0.339427  0.215944  0.094704 -0.023354  0.030892    2.69  \n1142 -0.465211  0.320198  0.044519  0.177840  0.261145 -0.143276    0.00  \n1143  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69  \n\n[1144 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>1.229658</td>\n      <td>0.141004</td>\n      <td>0.045371</td>\n      <td>1.202613</td>\n      <td>0.191881</td>\n      <td>0.272708</td>\n      <td>-0.005159</td>\n      <td>0.081213</td>\n      <td>0.464960</td>\n      <td>...</td>\n      <td>-0.219633</td>\n      <td>-0.167716</td>\n      <td>-0.270710</td>\n      <td>-0.154104</td>\n      <td>-0.780055</td>\n      <td>0.750137</td>\n      <td>-0.257237</td>\n      <td>0.034507</td>\n      <td>0.005168</td>\n      <td>4.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>266</td>\n      <td>1.289673</td>\n      <td>-0.694399</td>\n      <td>0.986683</td>\n      <td>-0.626997</td>\n      <td>-1.561741</td>\n      <td>-0.612824</td>\n      <td>-0.949037</td>\n      <td>0.068872</td>\n      <td>-0.744016</td>\n      <td>...</td>\n      <td>-0.485382</td>\n      <td>-0.411943</td>\n      <td>-0.812048</td>\n      <td>0.217873</td>\n      <td>0.515077</td>\n      <td>-0.174402</td>\n      <td>0.828402</td>\n      <td>-0.039262</td>\n      <td>0.013061</td>\n      <td>14.90</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>488</td>\n      <td>0.986168</td>\n      <td>-0.550923</td>\n      <td>1.140934</td>\n      <td>0.757901</td>\n      <td>-1.038890</td>\n      <td>0.476782</td>\n      <td>-0.837096</td>\n      <td>0.433228</td>\n      <td>0.896975</td>\n      <td>...</td>\n      <td>-0.106760</td>\n      <td>0.003400</td>\n      <td>-0.001184</td>\n      <td>0.017652</td>\n      <td>0.026666</td>\n      <td>0.078602</td>\n      <td>0.328056</td>\n      <td>0.008762</td>\n      <td>0.020131</td>\n      <td>64.99</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>-0.580629</td>\n      <td>0.482684</td>\n      <td>1.333123</td>\n      <td>-0.253080</td>\n      <td>-0.028469</td>\n      <td>-0.519166</td>\n      <td>0.503249</td>\n      <td>0.117773</td>\n      <td>0.117112</td>\n      <td>...</td>\n      <td>-0.298751</td>\n      <td>-0.042142</td>\n      <td>-0.148707</td>\n      <td>0.001451</td>\n      <td>0.302764</td>\n      <td>-0.680714</td>\n      <td>-0.015554</td>\n      <td>-0.006307</td>\n      <td>0.164222</td>\n      <td>21.66</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>156</td>\n      <td>-3.494861</td>\n      <td>-2.894450</td>\n      <td>1.637989</td>\n      <td>-0.274976</td>\n      <td>-0.389203</td>\n      <td>-0.703275</td>\n      <td>0.444194</td>\n      <td>0.154266</td>\n      <td>0.695818</td>\n      <td>...</td>\n      <td>0.670036</td>\n      <td>0.017010</td>\n      <td>-0.063521</td>\n      <td>0.676254</td>\n      <td>0.596377</td>\n      <td>0.114229</td>\n      <td>0.834915</td>\n      <td>0.309675</td>\n      <td>0.632261</td>\n      <td>500.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1139</th>\n      <td>539</td>\n      <td>-1.738582</td>\n      <td>0.052740</td>\n      <td>1.187057</td>\n      <td>-0.656652</td>\n      <td>0.920623</td>\n      <td>-0.291788</td>\n      <td>0.269083</td>\n      <td>0.140631</td>\n      <td>0.023464</td>\n      <td>...</td>\n      <td>0.002974</td>\n      <td>-0.179545</td>\n      <td>-0.192036</td>\n      <td>-0.261879</td>\n      <td>-0.237477</td>\n      <td>-0.335040</td>\n      <td>0.240323</td>\n      <td>-0.345129</td>\n      <td>-0.383563</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>1140</th>\n      <td>529</td>\n      <td>-2.000567</td>\n      <td>-2.495484</td>\n      <td>2.467149</td>\n      <td>1.140053</td>\n      <td>2.462010</td>\n      <td>0.594262</td>\n      <td>-2.110183</td>\n      <td>0.788347</td>\n      <td>0.958809</td>\n      <td>...</td>\n      <td>0.620899</td>\n      <td>0.422452</td>\n      <td>1.195394</td>\n      <td>0.297836</td>\n      <td>-0.857105</td>\n      <td>-0.219322</td>\n      <td>0.861019</td>\n      <td>-0.124622</td>\n      <td>-0.171060</td>\n      <td>1.50</td>\n    </tr>\n    <tr>\n      <th>1141</th>\n      <td>118</td>\n      <td>1.254914</td>\n      <td>0.350287</td>\n      <td>0.302488</td>\n      <td>0.693114</td>\n      <td>-0.371470</td>\n      <td>-1.070256</td>\n      <td>0.086781</td>\n      <td>-0.202836</td>\n      <td>0.035154</td>\n      <td>...</td>\n      <td>-0.079756</td>\n      <td>-0.287592</td>\n      <td>-0.832682</td>\n      <td>0.128083</td>\n      <td>0.339427</td>\n      <td>0.215944</td>\n      <td>0.094704</td>\n      <td>-0.023354</td>\n      <td>0.030892</td>\n      <td>2.69</td>\n    </tr>\n    <tr>\n      <th>1142</th>\n      <td>406</td>\n      <td>-2.312227</td>\n      <td>1.951992</td>\n      <td>-1.609851</td>\n      <td>3.997906</td>\n      <td>-0.522188</td>\n      <td>-1.426545</td>\n      <td>-2.537387</td>\n      <td>1.391657</td>\n      <td>-2.770089</td>\n      <td>...</td>\n      <td>0.126911</td>\n      <td>0.517232</td>\n      <td>-0.035049</td>\n      <td>-0.465211</td>\n      <td>0.320198</td>\n      <td>0.044519</td>\n      <td>0.177840</td>\n      <td>0.261145</td>\n      <td>-0.143276</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1143</th>\n      <td>0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.069083</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n    </tr>\n  </tbody>\n</table>\n<p>1144 rows × 30 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y_over","metadata":{"execution":{"iopub.status.busy":"2023-02-19T18:50:35.684101Z","iopub.execute_input":"2023-02-19T18:50:35.684358Z","iopub.status.idle":"2023-02-19T18:50:35.692284Z","shell.execute_reply.started":"2023-02-19T18:50:35.684335Z","shell.execute_reply":"2023-02-19T18:50:35.690618Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0       0\n1       0\n2       0\n3       0\n4       0\n       ..\n1139    1\n1140    1\n1141    1\n1142    1\n1143    1\nName: Class, Length: 1144, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_over=pd.concat([x_over,y_over],axis=1)\ndf_over","metadata":{"execution":{"iopub.status.busy":"2023-02-19T18:50:35.693624Z","iopub.execute_input":"2023-02-19T18:50:35.694051Z","iopub.status.idle":"2023-02-19T18:50:35.727639Z","shell.execute_reply.started":"2023-02-19T18:50:35.693992Z","shell.execute_reply":"2023-02-19T18:50:35.726856Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"      Time        V1        V2        V3        V4        V5        V6  \\\n0        4  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708   \n1      266  1.289673 -0.694399  0.986683 -0.626997 -1.561741 -0.612824   \n2      488  0.986168 -0.550923  1.140934  0.757901 -1.038890  0.476782   \n3       48 -0.580629  0.482684  1.333123 -0.253080 -0.028469 -0.519166   \n4      156 -3.494861 -2.894450  1.637989 -0.274976 -0.389203 -0.703275   \n...    ...       ...       ...       ...       ...       ...       ...   \n1139   539 -1.738582  0.052740  1.187057 -0.656652  0.920623 -0.291788   \n1140   529 -2.000567 -2.495484  2.467149  1.140053  2.462010  0.594262   \n1141   118  1.254914  0.350287  0.302488  0.693114 -0.371470 -1.070256   \n1142   406 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n1143     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n\n            V7        V8        V9  ...       V21       V22       V23  \\\n0    -0.005159  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104   \n1    -0.949037  0.068872 -0.744016  ... -0.411943 -0.812048  0.217873   \n2    -0.837096  0.433228  0.896975  ...  0.003400 -0.001184  0.017652   \n3     0.503249  0.117773  0.117112  ... -0.042142 -0.148707  0.001451   \n4     0.444194  0.154266  0.695818  ...  0.017010 -0.063521  0.676254   \n...        ...       ...       ...  ...       ...       ...       ...   \n1139  0.269083  0.140631  0.023464  ... -0.179545 -0.192036 -0.261879   \n1140 -2.110183  0.788347  0.958809  ...  0.422452  1.195394  0.297836   \n1141  0.086781 -0.202836  0.035154  ... -0.287592 -0.832682  0.128083   \n1142 -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n1143 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n\n           V24       V25       V26       V27       V28  Amount  Class  \n0    -0.780055  0.750137 -0.257237  0.034507  0.005168    4.99      0  \n1     0.515077 -0.174402  0.828402 -0.039262  0.013061   14.90      0  \n2     0.026666  0.078602  0.328056  0.008762  0.020131   64.99      0  \n3     0.302764 -0.680714 -0.015554 -0.006307  0.164222   21.66      0  \n4     0.596377  0.114229  0.834915  0.309675  0.632261  500.00      0  \n...        ...       ...       ...       ...       ...     ...    ...  \n1139 -0.237477 -0.335040  0.240323 -0.345129 -0.383563    1.00      1  \n1140 -0.857105 -0.219322  0.861019 -0.124622 -0.171060    1.50      1  \n1141  0.339427  0.215944  0.094704 -0.023354  0.030892    2.69      1  \n1142  0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n1143 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      1  \n\n[1144 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>1.229658</td>\n      <td>0.141004</td>\n      <td>0.045371</td>\n      <td>1.202613</td>\n      <td>0.191881</td>\n      <td>0.272708</td>\n      <td>-0.005159</td>\n      <td>0.081213</td>\n      <td>0.464960</td>\n      <td>...</td>\n      <td>-0.167716</td>\n      <td>-0.270710</td>\n      <td>-0.154104</td>\n      <td>-0.780055</td>\n      <td>0.750137</td>\n      <td>-0.257237</td>\n      <td>0.034507</td>\n      <td>0.005168</td>\n      <td>4.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>266</td>\n      <td>1.289673</td>\n      <td>-0.694399</td>\n      <td>0.986683</td>\n      <td>-0.626997</td>\n      <td>-1.561741</td>\n      <td>-0.612824</td>\n      <td>-0.949037</td>\n      <td>0.068872</td>\n      <td>-0.744016</td>\n      <td>...</td>\n      <td>-0.411943</td>\n      <td>-0.812048</td>\n      <td>0.217873</td>\n      <td>0.515077</td>\n      <td>-0.174402</td>\n      <td>0.828402</td>\n      <td>-0.039262</td>\n      <td>0.013061</td>\n      <td>14.90</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>488</td>\n      <td>0.986168</td>\n      <td>-0.550923</td>\n      <td>1.140934</td>\n      <td>0.757901</td>\n      <td>-1.038890</td>\n      <td>0.476782</td>\n      <td>-0.837096</td>\n      <td>0.433228</td>\n      <td>0.896975</td>\n      <td>...</td>\n      <td>0.003400</td>\n      <td>-0.001184</td>\n      <td>0.017652</td>\n      <td>0.026666</td>\n      <td>0.078602</td>\n      <td>0.328056</td>\n      <td>0.008762</td>\n      <td>0.020131</td>\n      <td>64.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>-0.580629</td>\n      <td>0.482684</td>\n      <td>1.333123</td>\n      <td>-0.253080</td>\n      <td>-0.028469</td>\n      <td>-0.519166</td>\n      <td>0.503249</td>\n      <td>0.117773</td>\n      <td>0.117112</td>\n      <td>...</td>\n      <td>-0.042142</td>\n      <td>-0.148707</td>\n      <td>0.001451</td>\n      <td>0.302764</td>\n      <td>-0.680714</td>\n      <td>-0.015554</td>\n      <td>-0.006307</td>\n      <td>0.164222</td>\n      <td>21.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>156</td>\n      <td>-3.494861</td>\n      <td>-2.894450</td>\n      <td>1.637989</td>\n      <td>-0.274976</td>\n      <td>-0.389203</td>\n      <td>-0.703275</td>\n      <td>0.444194</td>\n      <td>0.154266</td>\n      <td>0.695818</td>\n      <td>...</td>\n      <td>0.017010</td>\n      <td>-0.063521</td>\n      <td>0.676254</td>\n      <td>0.596377</td>\n      <td>0.114229</td>\n      <td>0.834915</td>\n      <td>0.309675</td>\n      <td>0.632261</td>\n      <td>500.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1139</th>\n      <td>539</td>\n      <td>-1.738582</td>\n      <td>0.052740</td>\n      <td>1.187057</td>\n      <td>-0.656652</td>\n      <td>0.920623</td>\n      <td>-0.291788</td>\n      <td>0.269083</td>\n      <td>0.140631</td>\n      <td>0.023464</td>\n      <td>...</td>\n      <td>-0.179545</td>\n      <td>-0.192036</td>\n      <td>-0.261879</td>\n      <td>-0.237477</td>\n      <td>-0.335040</td>\n      <td>0.240323</td>\n      <td>-0.345129</td>\n      <td>-0.383563</td>\n      <td>1.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1140</th>\n      <td>529</td>\n      <td>-2.000567</td>\n      <td>-2.495484</td>\n      <td>2.467149</td>\n      <td>1.140053</td>\n      <td>2.462010</td>\n      <td>0.594262</td>\n      <td>-2.110183</td>\n      <td>0.788347</td>\n      <td>0.958809</td>\n      <td>...</td>\n      <td>0.422452</td>\n      <td>1.195394</td>\n      <td>0.297836</td>\n      <td>-0.857105</td>\n      <td>-0.219322</td>\n      <td>0.861019</td>\n      <td>-0.124622</td>\n      <td>-0.171060</td>\n      <td>1.50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1141</th>\n      <td>118</td>\n      <td>1.254914</td>\n      <td>0.350287</td>\n      <td>0.302488</td>\n      <td>0.693114</td>\n      <td>-0.371470</td>\n      <td>-1.070256</td>\n      <td>0.086781</td>\n      <td>-0.202836</td>\n      <td>0.035154</td>\n      <td>...</td>\n      <td>-0.287592</td>\n      <td>-0.832682</td>\n      <td>0.128083</td>\n      <td>0.339427</td>\n      <td>0.215944</td>\n      <td>0.094704</td>\n      <td>-0.023354</td>\n      <td>0.030892</td>\n      <td>2.69</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1142</th>\n      <td>406</td>\n      <td>-2.312227</td>\n      <td>1.951992</td>\n      <td>-1.609851</td>\n      <td>3.997906</td>\n      <td>-0.522188</td>\n      <td>-1.426545</td>\n      <td>-2.537387</td>\n      <td>1.391657</td>\n      <td>-2.770089</td>\n      <td>...</td>\n      <td>0.517232</td>\n      <td>-0.035049</td>\n      <td>-0.465211</td>\n      <td>0.320198</td>\n      <td>0.044519</td>\n      <td>0.177840</td>\n      <td>0.261145</td>\n      <td>-0.143276</td>\n      <td>0.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1143</th>\n      <td>0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1144 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Determine the required sample size for the minority class using Cochran's formula\np = 0.5   #p=0.5 as exactly half of our dataset lies in strata 0 and the rest in strata 1\nz = 1.96 # z-score for 95% confidence level\nm = 0.05 # margin of error\nn1 = int(np.ceil((z**2 * 0.1 * (1-0.1)) / (m**2)))\nn2 = int(np.ceil((z**2 * 0.06 * (1-0.06)) / (m**2)))\nn3 = int(np.ceil((z**2 * 0.05 * (1-0.05)) / (m**2)))\nn4 = int(np.ceil((z**2 * 0.05 * (1-0.05)) / (m**2)))\nn5 = int(np.ceil((z**2 * 0.05 * (1-0.05)) / (m**2)))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T18:50:35.728700Z","iopub.execute_input":"2023-02-19T18:50:35.729175Z","iopub.status.idle":"2023-02-19T18:50:35.736037Z","shell.execute_reply.started":"2023-02-19T18:50:35.729149Z","shell.execute_reply":"2023-02-19T18:50:35.735068Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!pip install lazypredict","metadata":{"execution":{"iopub.status.busy":"2023-02-19T18:50:35.737308Z","iopub.execute_input":"2023-02-19T18:50:35.738127Z","iopub.status.idle":"2023-02-19T18:50:44.416724Z","shell.execute_reply.started":"2023-02-19T18:50:35.738100Z","shell.execute_reply":"2023-02-19T18:50:44.415175Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nRequirement already satisfied: lazypredict in /opt/conda/lib/python3.7/site-packages (0.2.12)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from lazypredict) (1.3.5)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from lazypredict) (1.0.1)\nRequirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (from lazypredict) (1.6.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from lazypredict) (1.0.2)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from lazypredict) (8.1.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from lazypredict) (4.64.1)\nRequirement already satisfied: lightgbm in /opt/conda/lib/python3.7/site-packages (from lazypredict) (3.3.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->lazypredict) (6.0.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from lightgbm->lazypredict) (1.7.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from lightgbm->lazypredict) (1.21.6)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm->lazypredict) (0.37.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->lazypredict) (3.1.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->lazypredict) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->lazypredict) (2022.2.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->lazypredict) (1.16.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->lazypredict) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->lazypredict) (3.8.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#using lazy predict to predict which models will give best accuracy.\nimport lazypredict\nfrom lazypredict.Supervised import LazyClassifier\nclf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\nmodels,predictions = clf.fit(x_over, x_test, y_over, y_test)\nmodels","metadata":{"execution":{"iopub.status.busy":"2023-02-19T18:50:44.417997Z","iopub.execute_input":"2023-02-19T18:50:44.418345Z","iopub.status.idle":"2023-02-19T18:50:47.643568Z","shell.execute_reply.started":"2023-02-19T18:50:44.418316Z","shell.execute_reply":"2023-02-19T18:50:47.642523Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 29/29 [00:03<00:00,  9.57it/s]\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\nModel                                                                           \nExtraTreesClassifier               0.99               0.50     0.50      0.98   \nXGBClassifier                      0.99               0.50     0.50      0.98   \nRandomForestClassifier             0.99               0.50     0.50      0.98   \nQuadraticDiscriminantAnalysis      0.99               0.50     0.50      0.98   \nDummyClassifier                    0.99               0.50     0.50      0.98   \nBaggingClassifier                  0.99               0.50     0.50      0.98   \nAdaBoostClassifier                 0.98               0.50     0.50      0.98   \nLGBMClassifier                     0.98               0.49     0.49      0.98   \nLabelPropagation                   0.97               0.49     0.49      0.98   \nLabelSpreading                     0.97               0.49     0.49      0.98   \nDecisionTreeClassifier             0.96               0.49     0.49      0.97   \nExtraTreeClassifier                0.96               0.48     0.48      0.97   \nSVC                                0.95               0.48     0.48      0.96   \nKNeighborsClassifier               0.94               0.48     0.48      0.96   \nSGDClassifier                      0.94               0.47     0.47      0.96   \nPerceptron                         0.94               0.47     0.47      0.96   \nGaussianNB                         0.93               0.47     0.47      0.96   \nNearestCentroid                    0.93               0.47     0.47      0.95   \nNuSVC                              0.92               0.46     0.46      0.95   \nPassiveAggressiveClassifier        0.91               0.46     0.46      0.94   \nLinearSVC                          0.91               0.46     0.46      0.94   \nCalibratedClassifierCV             0.90               0.45     0.45      0.94   \nLogisticRegression                 0.89               0.45     0.45      0.93   \nRidgeClassifier                    0.84               0.42     0.42      0.90   \nRidgeClassifierCV                  0.84               0.42     0.42      0.90   \nLinearDiscriminantAnalysis         0.83               0.42     0.42      0.90   \nBernoulliNB                        0.78               0.39     0.39      0.87   \n\n                               Time Taken  \nModel                                      \nExtraTreesClassifier                 0.15  \nXGBClassifier                        0.31  \nRandomForestClassifier               0.23  \nQuadraticDiscriminantAnalysis        0.01  \nDummyClassifier                      0.01  \nBaggingClassifier                    0.06  \nAdaBoostClassifier                   0.20  \nLGBMClassifier                       0.92  \nLabelPropagation                     0.08  \nLabelSpreading                       0.17  \nDecisionTreeClassifier               0.02  \nExtraTreeClassifier                  0.01  \nSVC                                  0.03  \nKNeighborsClassifier                 0.03  \nSGDClassifier                        0.02  \nPerceptron                           0.01  \nGaussianNB                           0.01  \nNearestCentroid                      0.03  \nNuSVC                                0.09  \nPassiveAggressiveClassifier          0.02  \nLinearSVC                            0.13  \nCalibratedClassifierCV               0.28  \nLogisticRegression                   0.06  \nRidgeClassifier                      0.02  \nRidgeClassifierCV                    0.02  \nLinearDiscriminantAnalysis           0.05  \nBernoulliNB                          0.01  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Balanced Accuracy</th>\n      <th>ROC AUC</th>\n      <th>F1 Score</th>\n      <th>Time Taken</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ExtraTreesClassifier</th>\n      <td>0.99</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.98</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>XGBClassifier</th>\n      <td>0.99</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.98</td>\n      <td>0.31</td>\n    </tr>\n    <tr>\n      <th>RandomForestClassifier</th>\n      <td>0.99</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.98</td>\n      <td>0.23</td>\n    </tr>\n    <tr>\n      <th>QuadraticDiscriminantAnalysis</th>\n      <td>0.99</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.98</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>DummyClassifier</th>\n      <td>0.99</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.98</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>BaggingClassifier</th>\n      <td>0.99</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.98</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>AdaBoostClassifier</th>\n      <td>0.98</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.98</td>\n      <td>0.20</td>\n    </tr>\n    <tr>\n      <th>LGBMClassifier</th>\n      <td>0.98</td>\n      <td>0.49</td>\n      <td>0.49</td>\n      <td>0.98</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>LabelPropagation</th>\n      <td>0.97</td>\n      <td>0.49</td>\n      <td>0.49</td>\n      <td>0.98</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>LabelSpreading</th>\n      <td>0.97</td>\n      <td>0.49</td>\n      <td>0.49</td>\n      <td>0.98</td>\n      <td>0.17</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeClassifier</th>\n      <td>0.96</td>\n      <td>0.49</td>\n      <td>0.49</td>\n      <td>0.97</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>ExtraTreeClassifier</th>\n      <td>0.96</td>\n      <td>0.48</td>\n      <td>0.48</td>\n      <td>0.97</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>SVC</th>\n      <td>0.95</td>\n      <td>0.48</td>\n      <td>0.48</td>\n      <td>0.96</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>KNeighborsClassifier</th>\n      <td>0.94</td>\n      <td>0.48</td>\n      <td>0.48</td>\n      <td>0.96</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>SGDClassifier</th>\n      <td>0.94</td>\n      <td>0.47</td>\n      <td>0.47</td>\n      <td>0.96</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>Perceptron</th>\n      <td>0.94</td>\n      <td>0.47</td>\n      <td>0.47</td>\n      <td>0.96</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>GaussianNB</th>\n      <td>0.93</td>\n      <td>0.47</td>\n      <td>0.47</td>\n      <td>0.96</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>NearestCentroid</th>\n      <td>0.93</td>\n      <td>0.47</td>\n      <td>0.47</td>\n      <td>0.95</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>NuSVC</th>\n      <td>0.92</td>\n      <td>0.46</td>\n      <td>0.46</td>\n      <td>0.95</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>PassiveAggressiveClassifier</th>\n      <td>0.91</td>\n      <td>0.46</td>\n      <td>0.46</td>\n      <td>0.94</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>LinearSVC</th>\n      <td>0.91</td>\n      <td>0.46</td>\n      <td>0.46</td>\n      <td>0.94</td>\n      <td>0.13</td>\n    </tr>\n    <tr>\n      <th>CalibratedClassifierCV</th>\n      <td>0.90</td>\n      <td>0.45</td>\n      <td>0.45</td>\n      <td>0.94</td>\n      <td>0.28</td>\n    </tr>\n    <tr>\n      <th>LogisticRegression</th>\n      <td>0.89</td>\n      <td>0.45</td>\n      <td>0.45</td>\n      <td>0.93</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifier</th>\n      <td>0.84</td>\n      <td>0.42</td>\n      <td>0.42</td>\n      <td>0.90</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifierCV</th>\n      <td>0.84</td>\n      <td>0.42</td>\n      <td>0.42</td>\n      <td>0.90</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>LinearDiscriminantAnalysis</th>\n      <td>0.83</td>\n      <td>0.42</td>\n      <td>0.42</td>\n      <td>0.90</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>BernoulliNB</th>\n      <td>0.78</td>\n      <td>0.39</td>\n      <td>0.39</td>\n      <td>0.87</td>\n      <td>0.01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"samplings = {\n    'Sampling1': NearMiss(),\n    'Sampling2': SMOTE(),\n    'Sampling3': RandomUnderSampler(),\n    'Sampling4': TomekLinks(),\n    'Sampling5': RandomOverSampler()\n    \n}\nmodels = {\n\n    'M1': LogisticRegression(),\n    'M2': lgb.LGBMClassifier(),\n    'M3': RandomForestClassifier(),\n    'M4': SVC(),\n    'M5': QuadraticDiscriminantAnalysis()\n    \n}\nsamples = {}    \nfor name, sampler in samplings.items():\n    x_resampled, y_resampled = sampler.fit_resample(x_train, y_train)\n    samples[name] = (x_resampled, y_resampled)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T18:50:47.647811Z","iopub.execute_input":"2023-02-19T18:50:47.648190Z","iopub.status.idle":"2023-02-19T18:50:47.719713Z","shell.execute_reply.started":"2023-02-19T18:50:47.648158Z","shell.execute_reply":"2023-02-19T18:50:47.718618Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Evaluate each model on each sampling technique\nresults = []\nfor sampler_name, sampler in samplings.items():\n    if sampler_name == 'Sampling1':\n        n = n1\n    elif sampler_name == 'Sampling2':\n        n = n2\n    elif sampler_name == 'Sampling3':\n        n = n3\n    elif sampler_name == 'Sampling4':\n        n = n4\n    else:\n        n = n5\n            \nresults = []\nfor model_name, model in models.items():\n    model_results = []\n    for name, (x_resampled, y_resampled) in samples.items():\n        model.fit(x_resampled, y_resampled)\n        y_pred = model.predict(x_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        model_results.append(accuracy)\n    results.append(model_results)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T18:50:47.721353Z","iopub.execute_input":"2023-02-19T18:50:47.721695Z","iopub.status.idle":"2023-02-19T18:50:51.238587Z","shell.execute_reply.started":"2023-02-19T18:50:47.721663Z","shell.execute_reply":"2023-02-19T18:50:51.237585Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Print the results in a table\ncolumns = ['NearMiss', 'SMOTE', 'RandomUnderSampler', 'TomekLinks', 'RandomOverSampler']\ndf_results = pd.DataFrame(results, index=['LogisticRegression', 'LGBMClassifier', 'RandomForestClassifier', 'SVC', 'QuadraticDiscriminantAnalysis'], columns=columns)\n\nformatted_results = df_results.applymap(lambda x: \"{:.7f}\".format(x))\ndisplay(formatted_results)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T18:50:51.239900Z","iopub.execute_input":"2023-02-19T18:50:51.240199Z","iopub.status.idle":"2023-02-19T18:50:51.262232Z","shell.execute_reply.started":"2023-02-19T18:50:51.240173Z","shell.execute_reply":"2023-02-19T18:50:51.261299Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                NearMiss      SMOTE RandomUnderSampler  \\\nLogisticRegression             0.5492228  0.8911917          0.7461140   \nLGBMClassifier                 0.9896373  0.9844560          0.9896373   \nRandomForestClassifier         0.6010363  0.9844560          0.7253886   \nSVC                            0.3678756  0.7461140          0.7098446   \nQuadraticDiscriminantAnalysis  0.0207254  0.9896373          0.1088083   \n\n                              TomekLinks RandomOverSampler  \nLogisticRegression             0.9896373         0.8808290  \nLGBMClassifier                 0.9896373         0.9896373  \nRandomForestClassifier         0.9896373         0.9896373  \nSVC                            0.9896373         0.7305699  \nQuadraticDiscriminantAnalysis  0.9896373         0.9896373  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NearMiss</th>\n      <th>SMOTE</th>\n      <th>RandomUnderSampler</th>\n      <th>TomekLinks</th>\n      <th>RandomOverSampler</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LogisticRegression</th>\n      <td>0.5492228</td>\n      <td>0.8911917</td>\n      <td>0.7461140</td>\n      <td>0.9896373</td>\n      <td>0.8808290</td>\n    </tr>\n    <tr>\n      <th>LGBMClassifier</th>\n      <td>0.9896373</td>\n      <td>0.9844560</td>\n      <td>0.9896373</td>\n      <td>0.9896373</td>\n      <td>0.9896373</td>\n    </tr>\n    <tr>\n      <th>RandomForestClassifier</th>\n      <td>0.6010363</td>\n      <td>0.9844560</td>\n      <td>0.7253886</td>\n      <td>0.9896373</td>\n      <td>0.9896373</td>\n    </tr>\n    <tr>\n      <th>SVC</th>\n      <td>0.3678756</td>\n      <td>0.7461140</td>\n      <td>0.7098446</td>\n      <td>0.9896373</td>\n      <td>0.7305699</td>\n    </tr>\n    <tr>\n      <th>QuadraticDiscriminantAnalysis</th>\n      <td>0.0207254</td>\n      <td>0.9896373</td>\n      <td>0.1088083</td>\n      <td>0.9896373</td>\n      <td>0.9896373</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}}]}